
               GMP SPEED MEASURING AND PARAMETER TUNING


The programs in this directory are for knowledgable users who want to make
measurements of the speed of GMP routines on their machine, and perhaps
tweak some settings or identify things that can be improved.

The programs here are tools, not ready to run solutions.  Nothing is built
in a normal "make all", follow the directions below.

Don't configure GMP with --enable-assert for this, since the extra code
added by assertion checking may influence measurements.



PARAMETER TUNING

The "tuneup" program runs some tests designed to find the best settings for
various thresholds, like KARATSUBA_MUL_THRESHOLD.  Its output can be put
into gmp-mparam.h.  The program can be built and run with

        make tune

If the thresholds indicated are grossly different to the values in the
selected gmp-mparam.h then you may get a performance boost in relevant size
ranges by changing gmp-mparam.h accordingly.

If your CPU has specific tuned parameters coming from one of the mpn
subdirectories then the values from "make tune" should be similar.  You can
submit new values if it looks like the current ones are out of date or
wildly wrong.  But check you're on the right CPU target and there aren't any
machine-specific effects causing a difference.

It's hoped the compiler used wont have too much effect on thresholds, since
for most CPUs they ultimately come down to comparisons between assembler
subroutines.  A particularly poor compiler might have an effect though.

Some thresholds produced by the tune program are merely single values chosen
from what's actually a range of sizes where two algorithms are pretty much
the same speed.  When this happens the program is likely to give slightly
different values on successive runs.

The karatsuba thresholds are generally sharply defined crossovers, the toom3
thresholds tend to have a range values.  The THRESHOLD EXAMINING section
below describes how to check this.



SPEED PROGRAM

The "speed" program can be used for measuring and comparing all sorts of
routines and producing tables of data or gnuplot graphs.  Compile it simply
with

	make speed

Here are some examples of how to use it.  See the speed.c code for all the
options.

Draw a graph of mpn_mul_n, stepping through sizes by 10 or a factor of 1.05
(whichever is greater).

        ./speed -s 10-5000 -t 10 -f 1.05 -P foo mpn_mul_n
	gnuplot foo.gnuplot

Compare mpn_add_n and mpn_lshift by 1, showing times in cycles and showing
under mpn_lshift the difference between it and mpn_add_n.

	./speed -s 1-40 -c -d mpn_add_n mpn_lshift.1

Using option -c for times in cycles is interesting but normally necessary
only when looking carefully at assembler subroutines.  You might think it
would always give an integer value, but this doesn't happen in practice,
probably due to overheads in the time measurements.

In the free-form output the "#" symbol against a measurement indicates the
corresponding routine is fastest at that speed.  This is a convenient visual
cue when comparing different routines.  The graph data files <name>.data
don't get this since it would upset gnuplot or other data viewers.

Potentially lots of things could be made available in this program, but it's
been left at only the things that have actually been wanted and that are
likely to be reasonably useful in the future.




TIME BASE

The time measuring method is determined in time.c, based on what the
configured target has available.  A microsecond accurate gettimeofday() will
work well, but there's code to use better methods, such as rdtsc in the x86
family (Pentium and up).

Currently, all the time measuring methods depend on the machine being
otherwise idle.  Measuring short routines (that complete within a timeslice)
may work at other times.  Some trouble is taken by speed_measure() in
common.c to avoid the ill effects of sporadic interrupts, or other
intermittent things like cron waking up every minute.  But generally you'll
want an idle machine for consistent results.

The CPU frequency is needed if times in cycles are to be displayed.  Or when
using a cycle counter like rdtsc it's always needed.  time.c knows how to
get the frequency on some systems, but when that fails, or needs to be
overridden, an environment variable GMP_CPU_FREQUENCY can be used (in
Hertz).  For example in bash on a 650MHz machine,

	export GMP_CPU_FREQUENCY=650e6

A high precision time base makes it possible to get accurate measurements in
a shorter time.  Support for systems and CPUs not already covered is wanted.




EXAMPLE COMPARISONS

Here are some ideas for things you can do with the speed program.

There's always going to be a certain amount of overhead in the time
measurements, due to reading the time base, and in the loop that runs a
routine enough times to get a reading of the desired precision.  Noop
functions taking various arguments are available to measure this.  The
"overhead" printed by the speed program each time in its intro is the "noop"
routine, but note that this is just for information, it isn't deducted from
the times printed or anything.

	./speed -s 1 noop noop_wxs noop_wxys

If you want to know how many cycles per limb a routine is taking, look at
the time increase when the size increments, using option -D.  This avoids
fixed overhead in the measuring.  Also, remember many of the assembler
routines have loops unrolled, so it might be necessary to compare times at,
say, 16, 32, 48, 64 etc limbs to see what the unrolled part is taking, as
opposed to any finishing off.

        ./speed -s 16-64 -t 16 -C -D mpn_add_n

The -C option on its own gives cycles per limb, but is really only useful at
big sizes where fixed overheads are small compared to the code doing the
real work.  Remember of course memory caching and possibly page swapping
will affect results at large sizes.

        ./speed -s 500000 -C mpn_add_n

Once a calculation stops fitting in the CPU data cache, it's going to start
taking longer.  Exactly where you'll see this happen depends on the cache
priming in speed_measure() or the routine being measured, and on what sort
of "least recently used" the cache does.  Here's an example for a CPU with a
16kbyte L1 data cache and 32-bit limb, showing a suddenly steeper curve for
mpn_add_n at about 2000 limbs.

        ./speed -s 1-4000 -t 5 -f 1.02 -P foo mpn_add_n
	gnuplot foo.gnuplot

When a routine has an unrolled loop for, say, multiples of 8 limbs and then
an ordinary loop for the remainder, it can happen that it's actually faster
to do an operation on, say, 8 limbs than it is on 7 limbs.  Here's an
example drawing a graph of mpn_sub_n, which you can look at to see if times
smoothly increase with size.

        ./speed -s 1-100 -c -P foo mpn_sub_n
	gnuplot foo.gnuplot

If mpn_lshift and mpn_rshift for your CPU have special case code for shifts
by 1, it ought to be faster (or at least not slower) than shifting by, say,
2 bits.

        ./speed -s 1-200 -c mpn_lshift.1 mpn_lshift.2
        ./speed -s 1-200 -c mpn_rshift.1 mpn_rshift.2

An mpn_lshift by 1 can be done by mpn_add_n adding a number to itself, and
if the former isn't faster there's an obvious improvement that's possible.

        ./speed -s 1-200 -c mpn_lshift.1 mpn_add_n_self

On some CPUs an "in-place" mpn_add_n where the destination is one of the
sources is faster than a separate destination.  (K6 for example.)  Here's an
example to see this.  (mpn_add_n_inplace is a special measuring routine, not
available for many other operations.)

        ./speed -s 1-200 -c mpn_add_n mpn_add_n_inplace

The gmp manual recommends divisions by a powers of two should be done using
a right shift because it'll be significantly faster.  Here's how you can see
by what factor mpn_rshift is faster, using division by 32 as an example.

        ./speed -s 1-200 -r mpn_rshift.5 mpn_divrem_1.32

mul_basecase takes an "r" parameter that's the first (larger) size
parameter.  For example to show speeds for 20x1 up to 20x15 operations in
cycles,

        ./speed -s 1-15 -c mpn_mul_basecase.20

mul_basecase with ".0" does an NxN multiply, so for example to show speeds
in cycles for 1x1, 2x2, 3x3, etc, up to 20x20, in cycles,

        ./speed -s 1-20 -c mpn_mul_basecase.0

sqr_basecase is implemented by a "triangular" method on most CPUs, making it
up to twice as fast as mul_basecase.  In practice loop overheads and the
products on the diagonal mean it falls short of this.  Here's an example
running the two showing by what factor an NxN mul_basecase is slower than an
NxN sqr_basecase.  (Some versions of sqr_basecase only on size below
KARATSUBA_SQR_THRESHOLD, so if it crashes at that point don't worry.)

        ./speed -s 1-20 -r mpn_sqr_basecase mpn_mul_basecase.0

The technique described above with -CD for showing the time difference in
cycles per limb between two size operations can be done on an NxN
mul_basecase using -E, which changes the basis for the size increment to
N*N.  For instance a 20x20 operation is taken to be doing 400 limbs, and a
16x16 doing 256 limbs.  The following therefore shows the per crossproduct
speed of mul_basecase and sqr_basecase at around 20x20 limbs.

        ./speed -s 16-20 -t 4 -CDE mpn_mul_basecase.0 mpn_sqr_basecase

Of course sqr_basecase isn't really doing NxN crossproducts, but it's useful
to compare it to mul_basecase as if it was.  For sqr_basecase the -F option
can be used to base the deltas on N*(N+1)/2 operations, which is the
triangular products sqr_basecase does.  For example,

        ./speed -s 16-20 -t 4 -CDF mpn_sqr_basecase

Both -E and -F are preliminary and might change.  A consistent approach to
using them when claiming certain per crossproduct or per triangularproduct
speeds hasn't really been established, but the increment between speeds in
the range karatsuba will call seems sensible, that being k to k/2.  For
instance, if the karatasuba threshold was 20 for the multiply and 30 for the
square,

        ./speed -s 10-20 -t 10 -CDE mpn_mul_basecase.0
        ./speed -s 15-30 -t 15 -CDF mpn_sqr_basecase




THRESHOLD EXAMINING

The speed program can be used to examine the speeds of different algorithms
to check the tune program has done the right thing.  For example to examine
the karatsuba multiply threshold,

	./speed -s 5-40 mpn_mul_basecase.0 mpn_kara_mul_n

When examining the toom3 threshold, remember it depends on the karatsuba
threshold, so the right karatsuba threshold needs to be compiled into the
library first.  The tune program uses special recompiled versions of
mpn/mul_n.c etc for this reason, but the speed program simply uses the
normal libgmp.la.  The BZ threshold depends on both the karatsuba and toom3
multiply thresholds.

Note further that the various routines may recurse into themselves on sizes
far enough above applicable thresholds.  For example, mpn_kara_mul_n will
recurse into itself on sizes greater than twice the compiled-in
KARATSUBA_MUL_THRESHOLD.

When doing the above comparison between mul_basecase and kara_mul_n what's
probably of interest is mul_basecase versus a kara_mul_n that does one level
of karatsuba then calls to mul_basecase, but this only happens on sizes less
than twice the compiled KARATSUBA_MUL_THRESHOLD.  A larger value for that
setting can be compiled-in to avoid the problem if necessary.  The same
applies to toom3 and BZ, though in a trickier fashion.

There are some upper limits on some of the thresholds, arising from arrays
dimensioned according to a threshold (mpn_mul_n), or asm code with certain
size displacements (some x86 versions of sqr_basecase).  So putting huge
values for the thresholds, even just for testing, may fail.




FUTURE

Versions of mul_basecase and sqr_basecase using the mpn calls or the
one-pass style, so the two can be compared.

Versions of mpn_divrem_1() using straight division versus a multiply by
inverse, so the two can be compared.

Measuring of udiv_qrnnd, udiv_qrnnd_preinv and udiv_qrnnd_preinv2norm to see
which is better.  Watch out for function call overhead when udiv_qrnnd is
actually an mpn_udiv_qrnnd subroutine.

Make an option in struct speed_parameters to specify the overlap, 0 for
none, 1 for dst=src1, 2 for dst=src2, 3 for dst1=src1 dst2=src2, 4 for
dst1=src2 dst2=src1.  This would be better than lots of _inplace versions of
measuring functions.

When speed_measure() does a division of total time measured by repetitions
performed, it divides the fixed overheads imposed by speed_starttime() and
speed_endtime().  When different routines are run with different repetitions
the overhead will then be differently counted.  It would improve precision
to try to avoid this.  Currently the idea is just to set speed_precision big
enough that the effect is insignificant compared to the routines being
measured.




----------------
Local variables:
mode: text
fill-column: 76
End:
