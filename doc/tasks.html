<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<html>
<head>
  <title>
    GMP Itemized Development Tasks
  </title>
</head>
<body bgcolor=lightgreen>

<center>
  <h1>
    GMP Itemized Development Tasks
  </h1>
</center>

<comment>
  An up-to-date html version of this file is available at
  <a href="http://www.swox.com/gmp/tasks.html">http://www.swox.com/gmp/tasks.html</a>.
</comment>

<p> This file lists itemized GMP development tasks.  Not all the tasks
    listed here are suitable for volunteers, but many of them are.
    Please see the <a href="projects.html">projects file</a> for more
    sizeable projects.

<h4>Correctness and Completeness</h4>
<ul>
<li> The various reuse.c tests need to force reallocation by calling
     <code>_mpz_realloc</code> with a small (1 limb) size.
<li> One reuse case is missing from mpX/tests/reuse.c: <code>mpz_XXX(a,a,a)</code>.
<li> When printing mpf_t numbers with exponents &gt;2^53 on machines with
     64-bit <code>mp_exp_t</code>, the precision of
     <code>__mp_bases[base].chars_per_bit_exactly</code> is insufficient and
     <code>mpf_get_str</code> aborts.  Detect and compensate.
<li> Make the string reading functions allow the `0x' prefix when the base is
     explicitly 16.  They currently only allow that prefix when the base is
     unspecified.
<li> In the development sources, we return abs(a%b) in the
     <code>mpz_*_ui</code> division routines.  Perhaps make them return the
     real remainder instead?  Changes return type to <code>signed long int</code>.
<li> <code>mpf_eq</code> is not always correct, when one operand is
     1000000000... and the other operand is 0111111111..., i.e., extremely
     close.  There is a special case in <code>mpf_sub</code> for this
     situation; put similar code in <code>mpf_eq</code>.
<li> <code>mpf_eq</code> doesn't implement what gmp.texi specifies.  It should
     not use just whole limbs, but partial limbs.
<li> NeXT has problems with newlines in asm strings in longlong.h.  Also,
     <code>__builtin_constant_p</code> is unavailable?  Same problem with MacOS
     X.
<li> Shut up SGI's compiler by declaring <code>dump_abort</code> in
     mp?/tests/*.c.
<li> <code>mpz_get_si</code> returns 0x80000000 for -0x100000000.
<li> <code>TMP_ALLOC</code> is not reentrant when using stack-alloc.c.  Perhaps
     make it so by default and leave a --enable-alloca=malloc-nonreentrant with
     the current code.  A reentrant version will probably be slower since it
     can't share malloced blocks across function calls.
<li> <code>mpz_scan0</code> and <code>mpz_scan1</code> only work in quite
     limited circumstances and could be improved.  Supporting twos complement
     like the other bitwise functions would be good.  A defined return value
     for no 0 or 1 found would be good too, perhaps <code>ULONG_MAX</code>.
</ul>



<h4>Machine Independent Optimization</h4>
<ul>
<li> <code>count_leading_zeros</code> returned count is checked for zero in
     hundreds of places.  Instead check the most significant bit of the
     operand, and avoid invoking <code>count_leading_zeros</code> if the bit is
     set.  This is an optimization on all machines, and significant on machines
     with slow <code>count_leading_zeros</code>.
<li> <code>count_trailing_zeros</code> is used on more or less uniformly
     distributed numbers in a couple of places.  For some CPUs
     <code>count_trailing_zeros</code> is slow and it's probably worth handling
     the frequently occurring 0 to 2 trailing zeros cases specially.
<li> Reorganize longlong.h so that we can inline the operations even for the
     system compiler.  When there is no such compiler feature, make calls to
     stub functions.  Write such stub functions for as many machines as
     possible.
<li> Rewrite <code>umul_ppmm</code> to use floating-point for generating the
     most significant limb (if <code>BITS_PER_MP_LIMB</code> &lt= 52 bits).
     (Peter Montgomery has some ideas on this subject.)
<li> Improve the default <code>umul_ppmm</code> code in longlong.h: Add partial
     products with fewer operations.
<li> Write new <code>mpn_get_str</code> and <code>mpn_set_str</code> running in
     the sub O(n^2) range, using some divide-and-conquer approach, preferably
     without using division.
<li> <code>mpn_get_str</code> should use a fast native
     <code>mpn_divrem_1</code> when available (athlon, p6mmx), possibly via a
     new <code>mpn_divrem_1_preinv</code> interface.  New functions like
     <code>mpn_divrem_1_norm</code> or <code>mpn_divrem_1_preinvnorm</code>
     could exist for those targets where pre-shifting helps (p6 maybe).
<li> Copy tricky code for converting a limb from development version of
     <code>mpn_get_str</code> to mpf/get_str.  (Talk to Torbjörn about this.)
<li> Consider inlining these functions: <code>mpz_size</code>,
     <code>mpz_set_ui</code>, <code>mpz_set_q</code>, <code>mpz_clear</code>,
     <code>mpz_init</code>, <code>mpz_get_ui</code>, <code>mpz_scan0</code>,
     <code>mpz_scan1</code>, <code>mpz_getlimbn</code>,
     <code>mpz_init_set_ui</code>, <code>mpz_perfect_square_p</code>,
     <code>mpz_popcount</code>, <code>mpf_size</code>,
     <code>mpf_get_prec</code>, <code>mpf_set_prec_raw</code>,
     <code>mpf_set_ui</code>, <code>mpf_init</code>, <code>mpf_init2</code>,
     <code>mpf_clear</code>, <code>mpf_set_si</code>.
<li> <code>mpz_powm</code> and <code>mpz_powm_ui</code> aren't very
     fast on one or two limb moduli, due to a lot of function call
     overheads.  These could perhaps be handled as special cases.
<li> <code>mpz_powm</code> and <code>mpz_powm_ui</code> want better
     algorithm selection, and the latter should use REDC.  Both could
     change to use an <code>mpn_powm</code> and <code>mpn_redc</code>.
<li> <code>mpz_powm</code> REDC should do multiplications by <code>g[]</code>
     using the division method when they're small, since the REDC form of a
     small multiplier is normally a full size product.  Probably would need a
     new tuned parameter to say what size multiplier is "small", as a function
     of the size of the modulus.
<li> <code>mpz_powm</code> REDC should handle even moduli if possible.  Maybe
     this would mean for m=n*2^k doing mod n using REDC and an auxiliary
     calculation mod 2^k, then putting them together at the end.
<li> <code>mpn_gcd</code> might be able to be sped up on small to
     moderate sizes by improving <code>find_a</code>, possibly just by
     providing an alternate implementation for CPUs with slowish
     <code>count_leading_zeros</code>.
<li> Toom3 <code>USE_MORE_MPN</code> could use a low to high cache localized
     evaluate and interpolate.  The necessary <code>mpn_divexact_by3c</code>
     exists.
<li> <code>mpn_mul_basecase</code> on NxM with big N but small M could try for
     better cache locality by taking N piece by piece.  The current code could
     be left available for CPUs without caching.  Depending how karatsuba etc
     is applied to unequal size operands it might be possible to assume M is
     always smallish.
<li> <code>mpn_perfect_square_p</code> on small operands might be better off
     skipping the residue tests and just taking a square root.
<li> <code>mpz_perfect_power_p</code> could be improved in a number of ways.
     Test for Nth power residues modulo small primes like
     <code>mpn_perfect_square_p</code> does.  Use p-adic arithmetic to find
     possible roots.  Negatives should be handled, and used to know the power
     must be odd.  <code>mpn_perfect_square_p</code> should be called to test
     for square roots.  Divisibility by powers of 2 should be tested with
     <code>mpz_scan1</code> or similar.  Divisibility by other primes should
     be tested by grouping into a limb like <code>PP</code>.
<li> <code>mpz_probab_prime_p</code>, <code>mpn_perfect_square_p</code> and
     <code>mpz_perfect_power_p</code> could take a remainder mod 2^24-1 to
     quickly get remainders mod 3, 5, 7, 13 and 17 (factors of 2^24-1).
<li> <code>mpf_set_str</code> produces low zero limbs when a string has a
     fraction but is exactly representable, eg. 0.5 in decimal.  These could be
     stripped to save work in later operations.
<li> <code>mpz_and</code>, <code>mpz_ior</code> and <code>mpz_xor</code> should
     use <code>mpn_and</code> etc for the benefit of the small number of
     targets with native versions of those routines.  Need to be careful not to
     pass size==0.  Is some code sharing possible between the <code>mpz</code>
     routines?
<li> <code>mpn_bdivmod</code> should use a divide and conquer like the normal
     division.  See "Exact Division with Karatsuba Complexity" by Jebelean for
     a (brief) description.  This will benefit <code>mpz_divexact</code>
     immediately, and <code>mpn_gcd</code> on large unequal size operands.
     REDC should be able to use it too.
<li> <code>mpn_gcd_1</code>, <code>mpz_kronecker_ui</code> etc should be able
     to do an exact division style reduction initially, rather than
     <code>mpn_mod_1</code>.  This would be the same as <code>mpn_gcd</code>
     does using <code>mpn_bdivmod</code>.  This is still two multiplies per
     limb, but is simpler and should be faster than mul by inverse division.
     Perhaps a function <code>mpn_modexact_1</code>, being the remainder part
     of an <code>mpn_divexact_1</code>.  Creating the modular inverse will take
     a few cycles, so it might be only for say 4 limbs and up.
</ul>


<h4>Machine Dependent Optimization</h4>
<ul>
<li> Run the `tune' utility for more compiler/CPU combinations.  We would like
     to have gmp-mparam.h files in practically every implementation specific
     mpn subdirectory, and repeat each *_THRESHOLD for gcc and the system
     compiler.  See the `tune' top-level directory for more information.
<li> Alpha: Rewrite <code>mpn_addmul_1</code>, <code>mpn_submul_1</code>, and
     <code>mpn_mul_1</code> for the 21264.  On 21264, they should run at 4, 3,
     and 3 cycles/limb respectively, if the code is unrolled properly.  (Ask
     Torbjörn for his xm.s and xam.s skeleton files.)
<li> Alpha: Rewrite <code>mpn_addmul_1</code>, <code>mpn_submul_1</code>, and
     <code>mpn_mul_1</code> for the 21164.  This should use both integer
     multiplies and floating-point multiplies.  For the floating-point
     operations, the single-limb multiplier should be split into three 21-bit
     chunks.
<li> UltraSPARC: Rewrite 64-bit <code>mpn_addmul_1</code>,
     <code>mpn_submul_1</code>, and <code>mpn_mul_1</code>.  Should use
     floating-point operations, and split the invariant single-limb multiplier
     into 21-bit chunks.  Should give about 18 cycles/limb, but the pipeline
     will become very deep.  (Torbjörn has C code that is useful as a starting
     point.)
<li> UltraSPARC: Rewrite <code>mpn_lshift</code> and <code>mpn_rshift</code>.
     Should give 2 cycles/limb.  (Torbjörn has code that just needs to be
     finished.)
<li> SPARC32/V9: Find out why the speed of <code>mpn_addmul_1</code>
     and the other multiplies varies so much on successive sizes.
<li> PA64: Improve <code>mpn_addmul_1</code>, <code>mpn_submul_1</code>, and
     <code>mpn_mul_1</code>.  The current development code runs at 11
     cycles/limb, which is already very good.  But it should be possible to
     saturate the cache, which will happen at 7.5 cycles/limb.
<li> UltraSPARC: Write <code>umul_ppmm</code>.  Important in particular for
     <code>mpn_sqr_basecase</code>.  Using four "<code>mulx</code>"s either
     with an asm block or via the generic C code is about 90 cycles.
<li> Implement <code>mpn_mul_basecase</code> and <code>mpn_sqr_basecase</code>
     for important machines.  Helping the generic sqr_basecase.c with an
     <code>mpn_sqr_diagonal</code> might be enough for some of the RISCs.
<li> POWER2/POWER2SC: Schedule <code>mpn_lshift</code>/<code>mpn_rshift</code>.
     Will bring time from 1.75 to 1.25 cycles/limb.
<li> X86: Optimize non-MMX <code>mpn_lshift</code> for shifts by 1.  (See Pentium code.)
<li> PentiumPro: <code>mpn_mod_1</code> can use a mul-by-inverse the same as
     P-II but without the shifts inside the loop and hence without MMX.  The
     same might speed up the loop for P-II also, but maybe at the cost of one
     extra division step.
<li> PentiumPro: <code>mpn_divrem_1</code> might be able to use a
     mul-by-inverse, hoping for maybe 30 c/l.
<li> P6: <code>mpn_add_n</code> and <code>mpn_sub_n</code> should be able to go
     faster than the generic x86 code at 3.5 c/l.  The athlon code for instance
     runs at about 2.7.
<li> PPC32: Try using fewer registers in the current <code>mpn_lshift</code>.
     The pipeline is now extremely deep, perhaps unnecessarily deep.
<li> PPC32: Write <code>mpn_rshift</code> based on new <code>mpn_lshift</code>.
<li> PPC32: Rewrite <code>mpn_add_n</code> and <code>mpn_sub_n</code>.  Should
     run at just 3.25 cycles/limb.  (Ask for xxx-add_n.s as a starting point.)
<li> Fujitsu VPP: Vectorize main functions, perhaps in assembly language.
<li> Fujitsu VPP: Write <code>mpn_mul_basecase</code> and
     <code>mpn_sqr_basecase</code>.  This should use a "vertical multiplication
     method", to avoid carry propagation.  splitting one of the operands in
     11-bit chunks.
<li> Cray: Vectorize main functions, perhaps in assembly language.
<li> Cray: Write <code>mpn_mul_basecase</code> and
     <code>mpn_sqr_basecase</code>.  Same comment applies to this as to the
     same functions for Fujitsu VPP.
<li> Improve <code>count_leading_zeros</code> for 64-bit machines:
  <pre>
	   if ((x &gt&gt 32) == 0) { x &lt&lt= 32; cnt += 32; }
	   if ((x &gt&gt 48) == 0) { x &lt&lt= 16; cnt += 16; }
	   ... </pre>

</ul>

<h4>New Functionality</h4>
<ul>
<li> <code>mpz_get_nth_ui</code>.  Return the nth word (not necessarily the nth limb).
<li> Maybe add <code>mpz_crr</code> (Chinese Remainder Reconstruction).
<li> Let `0b' and `0B' mean binary input everywhere.
<li> Maybe make <code>mpz_init</code> (and <code>mpq_init</code>) do lazy
     allocation.  Set <code>ALLOC(var)</code> to 0, and have
     <code>mpz_realloc</code> special-handle that case.  Update functions that
     rely on a single limb (like <code>mpz_set_ui</code>,
     <code>mpz_{t,f,c}div_{qr,r}_ui</code>, and others).
<li> Add <code>mpf_out_raw</code> and <code>mpf_inp_raw</code>.  Make sure
     format is portable between 32-bit and 64-bit machines, and between
     little-endian and big-endian machines.
<li> Handle numeric exceptions: Call an error handler, and/or set
     <code>gmp_errno</code>.
<li> Implement <code>gmp_fprintf</code>, <code>gmp_sprintf</code>, and
     <code>gmp_snprintf</code>.  Think about some sort of wrapper
     around <code>printf</code> so it and its several variants don't
     have to be completely reimplemented.
<li> Implement some <code>mpq</code> input and output functions.
<li> Implement a full precision <code>mpz_kronecker</code>, leave
     <code>mpz_jacobi</code> for compatibility.
<li> Make the mpn logops and copys available in gmp.h.  Since they can
     be either library functions or inlines, gmp.h would need to be
     generated from a gmp.in based on what's in the library.  gmp.h
     would still be compiler-independent though.
<li> Make versions of <code>mpz_set_str</code> etc taking string
     lengths rather than null-terminators.
<li> Consider changing the thresholds to apply the simpler algorithm when
     "<code>&lt;=</code>" rather than "<code>&lt;</code>", so a threshold can
     be set to <code>MP_SIZE_T_MAX</code> to get only the simpler code (the
     compiler will know <code>size &lt;= MP_SIZE_T_MAX</code> is always true).
<li> <code>mpz_cdiv_q_2exp</code> and <code>mpz_cdiv_r_2exp</code>
     could be implemented to match the corresponding tdiv and fdiv.
     Maybe some code sharing is possible.
<li> <code>mpz_powm</code> could handle negative exponents by powering the
     modular inverse of the base.  But what to do if an inverse doesn't exist
     (base and modulus have common factors)?  Throw a divide by zero maybe, or
     return a flag like <code>mpz_invert</code> does.
</ul>


<h4>Configuration</h4>

<ul>
<li> Determine floating-point format with a feature test.  Get rid of large
     #ifdef mess for FP format in gmp-impl.h.
<li> HPPA: config.guess should recognize 7000, 7100, 7200, and 8x00.
<li> Mips: config.guess should say mipsr3000, mipsr4000, mipsr10000, etc.
     "hinv -c processor" gives lots of information on Irix.
<li> Power: config.guess might be able to use AIX 4
     <code>_system_configuration.implementation</code> for more accurate CPU
     determination.
<li> Sparc: config.guess should say supersparc, microsparc, ultrasparc1,
     ultrasparc2, etc.  "prtconf -vp" gives lots of information about a
     Solaris system.
<li> Sparc32: floating point or integer <code>udiv</code> should be selected
     according to the CPU target.  Currently floating point ends up being
     used on all sparcs, which is probably not right for generic V7 and V8.
<li> Extend the "optional" compiler arguments to choose the first that works
     from from a set, so when gcc gets athlon support it can try
     -mcpu=athlon, -mcpu=pentiumpro, or -mcpu=i486, whichever works.
<li> Build multiple variants of the library under certain systems.  An
     example is -n32 and -64 on Irix.
<li> There are a few filenames that don't fit in 14 chars, if this matters.
<li> Enable support for FORTRAN versions of mpn files (eg. for
     mpn/cray/mulww.f).  Add "f" to MPN_SUFFIXES, run <code>AC_PROG_F77</code>
     if such a file is found.  Automake will generate some of what's needed in
     the makefiles, but libtool doesn't know fortran and so rules like the
     current ".asm.lo" will be needed.
<li> Configure in demos directory.  Now pexpr.c is becoming the usual *nix
     mess of nested ifdefs.
<li> Some CPUs have <code>umul</code> and <code>udiv</code> code not being
     used.  Check all such for bit rot and then put umul and udiv in
     <code>$gmp_mpn_functions_optional</code> as "standard optional" objects.
     <br> In particular Sparc and SparcV8 on non-gcc should benefit from
     umul.asm enabled; the generic umul is suspected to be making sqr_basecase
     slower than mul_basecase.
<li> HPPA <code>mpn_umul_ppmm</code> and <code>mpn_udiv_qrnnd</code> have a
     different parameter order than those functions on other CPUs.  It might
     avoid confusion to have them under different names, maybe
     <code>mpn_umul_ppmm_plast</code> or some such.  Prototypes then wouldn't
     be conditionalized, and the appropriate form could be selected with the
     <code>HAVE_NATIVE</code> scheme if/when the code switches to use a
     <code>PROLOGUE</code> style.
<li> Think about a --enable-abi=FOO to select which abi to use on systems that
     support multiple calling conventions and/or data sizes.  The default could
     be "guess", other choices could be made by users wanting compatibility
     with other object code.  Doing the right thing with where and how to
     install library files probably needs a lot of help from automake and
     libtool.  A few simple cases like /usr/lib/sparcv9 might be easy enough
     though.
</ul>

<p> In general, getting the exact right configuration, passing the
exact right options to the compiler, etc, might mean that the GMP
performance more than doubles.

<p> When testing, make sure to test at least the following for all out
target machines: (1) Both gcc and cc (and c89).  (2) Both 32-bit mode
and 64-bit mode (such as -n32 vs -64 under Irix). (3) Both the system
`make' and GNU `make'. (4) With and without GNU binutils.


<h4>Miscellaneous</h4>
<ul>
<li> Make <code>mpz_div</code> and <code>mpz_divmod</code> use rounding
     analogous to <code>mpz_mod</code>.  Document, and list as an
     incompatibility.
<li> Maybe make mpz/pow_ui.c more like mpz/ui_pow_ui.c, or write new
     mpn/generic/pow_ui.
<li> <code>mpz_invert</code> should call <code>mpn_gcdext</code> directly.
</ul>


<h4>Aids to Debugging</h4>
<ul>
<li> <code>TMP_ALLOC</code> could do a separate <code>malloc</code> for each
     allocated block, to help a redzoning malloc debugger.  Perhaps a config
     option --enable-alloca=debug.
<li> Add <code>ASSERT</code>s at the start of each user-visible
     mpz/mpq/mpf function to check the validity of each
     <code>mp?_t</code> parameter, in particular to check they've been
     <code>mp?_init</code>ed.  This might catch elementary mistakes in
     user programs.  Care would need to be taken over
     <code>MPZ_TMP_INIT</code>ed variables used internally.
<li> The test programs could use <code>mp_set_memory_functions</code> and a
     check at program end to guard against memory leaks.  This could also check
     that the sizes passed to allocate and free are the same.
</ul>


<h4>Documentation</h4>
<ul>
<li> Document conventions, like that <code> unsigned long int</code> is used for
     bit counts/ranges, and that <code>mp_size_t</code> is used for limb counts.
<li> <code>mpz_inp_str</code> (etc) doesn't say when it stops reading digits.
</ul>

<hr>

<table width="100%">
  <tr>
    <td>
      <font size=2>
      Please send comments about this page to
      <a href="mailto:tege@swox.com">tege@swox.com</a>.<br>
      Copyright 1999, 2000 Torbjörn Granlund.
      </font>
    </td>
    <td align=right>
    </td>
  </tr>
</table>

</body>
</html>
